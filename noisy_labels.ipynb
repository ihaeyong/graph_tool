{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from lib.word_vectors import obj_edge_vectors\n",
    "ftensor = torch.FloatTensor\n",
    "ltensor = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_batch(subj_dists, obj_dists, batch, num_ent, _cb_var, _cb_mode='head-tail-cor'):\n",
    "    # batch: ltensor type, contains positive triplets\n",
    "    batch_size, _ = batch.size()\n",
    "    \n",
    "    corrupted = batch.clone()\n",
    "\n",
    "    if len(_cb_var) == 0:\n",
    "        _cb_var.append(ltensor(batch_size//2).cuda())\n",
    "        #_cb_var.append(ltensor(batch_size//2))\n",
    "        \n",
    "    q_samples_l = _cb_var[0].random_(0, num_ent)\n",
    "    q_samples_r = _cb_var[0].random_(0, num_ent)\n",
    "\n",
    "    if _cb_mode == 'head-cor':\n",
    "        #head-corrupted\n",
    "        corrupted[:batch_size//2, 0] = q_samples_l\n",
    "    elif _cb_mode == 'tail-cor':\n",
    "        #tail-corrupted\n",
    "        corrupted[batch_size//2:, 2] = q_samples_r\n",
    "    elif _cb_mode == 'head-tail-cor':\n",
    "        #head-tail-corrupted\n",
    "        corrupted[:batch_size//2, 0] = q_samples_l\n",
    "        corrupted[batch_size//2:, 2] = q_samples_r\n",
    "\n",
    "    return corrupted.contiguous(), torch.cat([q_samples_l, q_samples_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_batch(subj_dists, obj_dists):\n",
    "    \n",
    "    subj_samples = torch.multinomial(subj_dists, 1).squeeze(1)\n",
    "    obj_samples = torch.multinomial(obj_dists, 1).squeeze(1)\n",
    "    \n",
    "    return subj_samples, obj_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  126     4   110\n",
      "  146    47    73\n",
      "   68     9   115\n",
      "   45     4    66\n",
      "  108    43   103\n",
      "  140    18    76\n",
      "   56    20    22\n",
      "   22    17    91\n",
      "   37     2     1\n",
      "   92    26    48\n",
      "[torch.LongTensor of size 10x3]\n",
      "\n",
      "\n",
      "   62     4   110\n",
      "   92    47    73\n",
      "  138     9   115\n",
      "   58     4    66\n",
      "   70    43   103\n",
      "  140    18    62\n",
      "   56    20    92\n",
      "   22    17   138\n",
      "   37     2    58\n",
      "   92    26    70\n",
      "[torch.LongTensor of size 10x3]\n",
      "\n",
      "\n",
      "  62\n",
      "  92\n",
      " 138\n",
      "  58\n",
      "  70\n",
      "  62\n",
      "  92\n",
      " 138\n",
      "  58\n",
      "  70\n",
      "[torch.cuda.LongTensor of size 10 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "  87\n",
      "  15\n",
      "   9\n",
      " 125\n",
      "  14\n",
      "  94\n",
      "  54\n",
      "   1\n",
      "  49\n",
      "  86\n",
      "[torch.LongTensor of size 10]\n",
      "\n",
      "Variable containing:\n",
      " 107\n",
      "  66\n",
      "  23\n",
      "  69\n",
      "  69\n",
      " 136\n",
      "  26\n",
      "  75\n",
      "   9\n",
      "  42\n",
      "[torch.LongTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    p= 1\n",
    "    num_ent = 151\n",
    "    num_rel = 51\n",
    "    embed_dim = 4096\n",
    "    \n",
    "    batch = 10\n",
    "    \n",
    "    subj_dists = Variable(torch.randn(batch,num_ent))\n",
    "    obj_dists = Variable(torch.randn(batch,num_ent))\n",
    "    \n",
    "    subj_dists = F.softmax(subj_dists,1)\n",
    "    obj_dists = F.softmax(obj_dists,1)\n",
    "    \n",
    "    lhs = torch.LongTensor(batch).random_(0,num_ent)\n",
    "    rhs = torch.LongTensor(batch).random_(0,num_ent)\n",
    "    rel = torch.LongTensor(batch).random_(0,num_rel)\n",
    "    \n",
    "    p_batch = torch.stack((lhs, rel, rhs),1)\n",
    "    print(p_batch)\n",
    "    \n",
    "    _cb_var = []\n",
    "    _cb_mode=['head-tail-cor','tail-cor','head-tail-cor']\n",
    "    \n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    nce_batch, q_samples = corrupt_batch(\n",
    "        subj_dists, obj_dists, p_batch, num_ent, _cb_var, _cb_mode[0]\n",
    "    )\n",
    "    \n",
    "    print(nce_batch)\n",
    "    print(q_samples)\n",
    "    \n",
    "    subj_labels, obj_labels = noisy_batch(subj_dists, obj_dists)\n",
    "    print(subj_labels)\n",
    "    print(obj_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'use_tran_vis', 'obj_embed', and 'rel_embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-be7b2838afb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mmargin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;31m#transrele = TransRelE(num_ent, num_rel, embed_dim, p)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mtransrele\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransRelD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarginRankingLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'use_tran_vis', 'obj_embed', and 'rel_embed'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from lib.word_vectors import obj_edge_vectors\n",
    "ftensor = torch.FloatTensor\n",
    "ltensor = torch.LongTensor\n",
    "\n",
    "import ipdb\n",
    "\n",
    "class MarginRankingLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(MarginRankingLoss, self).__init__()\n",
    "        #ipdb.set_trace()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, p_enrgs, l_enrgs, ln_enrgs, weights=None):\n",
    "        #ipdb.set_trace()\n",
    "        # output: pl_rel_term, lnl_rel_term\n",
    "        # input: p_rel_enrgs, l_rel_enrgs, nl_rel_enrgs\n",
    "        scores_pl = (self.margin + p_enrgs - ln_enrgs).clamp(min=0)\n",
    "        #scores_lnl = (self.margin + l_enrgs - ln_enrgs).clamp(min=0)\n",
    "        \n",
    "        if weights is not None:\n",
    "            scores_pl = scores_pl * weights / weights.mean()\n",
    "            #scores_lnl = scores_lnl * weights / weights.mean()\n",
    "            \n",
    "        scores_lnl = None\n",
    "        \n",
    "        return scores_pl.mean(), scores_lnl\n",
    "        #return scores_pl.mean(), scores_lnl.mean()\n",
    "    \n",
    "def corrupt_batch(batch, num_ent, _cb_var, _cb_mode='head-tail-cor'):\n",
    "    # batch: ltensor type, contains positive triplets\n",
    "    batch_size, _ = batch.size()\n",
    "    \n",
    "    corrupted = batch.clone()\n",
    "\n",
    "    if len(_cb_var) == 0:\n",
    "        _cb_var.append(ltensor(batch_size//2).cuda())\n",
    "        #_cb_var.append(ltensor(batch_size//2))\n",
    "\n",
    "    q_samples_l = _cb_var[0].random_(0, num_ent)\n",
    "    q_samples_r = _cb_var[0].random_(0, num_ent)\n",
    "    \n",
    "    if _cb_mode == 'head-cor':\n",
    "        #head-corrupted\n",
    "        corrupted[:batch_size//2, 0] = q_samples_l\n",
    "    elif _cb_mode == 'tail-cor':\n",
    "        #tail-corrupted\n",
    "        corrupted[batch_size//2:, 2] = q_samples_r\n",
    "    elif _cb_mode == 'head-tail-cor':\n",
    "        #head-tail-corrupted\n",
    "        corrupted[:batch_size//2, 0] = q_samples_l\n",
    "        corrupted[batch_size//2:, 2] = q_samples_r\n",
    "\n",
    "    return corrupted.contiguous(), torch.cat([q_samples_l, q_samples_r])\n",
    "\n",
    "class TransRelE(nn.Module):\n",
    "    def __init__(self, num_ent, num_rel, embed_dim, p):\n",
    "        super(TransRelE, self).__init__()\n",
    "        self.num_ent = num_ent\n",
    "        self.num_rel = num_rel\n",
    "        self.embed_dim = embed_dim\n",
    "        self.p = p\n",
    "\n",
    "        r = 6 / np.sqrt(self.embed_dim)\n",
    "        self.ent_embeds = nn.Embedding(self.num_ent, self.embed_dim, max_norm=1, norm_type=2, sparse=True)\n",
    "        self.rel_embeds = nn.Embedding(self.num_rel, self.embed_dim, max_norm=1, norm_type=2, sparse=True)\n",
    "\n",
    "        self.ent_embeds.weight.data.uniform_(-r, r)#.renorm_(p=2, dim=1, maxnorm=1)\n",
    "        self.rel_embeds.weight.data.uniform_(-r, r)#.renorm_(p=2, dim=1, maxnorm=1)\n",
    "        \n",
    "\n",
    "    def forward(self, triplets):\n",
    "\n",
    "        lhs_idxs = triplets[:, 0]\n",
    "        rel_idxs = triplets[:, 1]\n",
    "        rhs_idxs = triplets[:, 2]\n",
    "        lhs_es = self.ent_embeds(lhs_idxs)\n",
    "        rel_es = self.rel_embeds(rel_idxs)\n",
    "        rhs_es = self.ent_embeds(rhs_idxs)\n",
    "\n",
    "        enrgs = (lhs_es + rel_es - rhs_es).norm(p=self.p, dim=1)\n",
    "        return enrgs, lhs_es, rhs_es, rel_es\n",
    "\n",
    "    def save(self, fn):\n",
    "        torch.save(self.state_dict(), fn)\n",
    "\n",
    "    def load(self, fn):\n",
    "        self.load_state_dict(torch.load(fn))\n",
    "\n",
    "\n",
    "class RotatE(nn.Module):\n",
    "    def __init__(self, classes, rel_classes, embed_dim, p, use_tran_vis, obj_embed, rel_embed, mode):\n",
    "        super(RotatE, self).__init__()\n",
    "        self.num_ent = len(classes)\n",
    "        self.num_rel = len(rel_classes)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.p = p\n",
    "        \n",
    "        self.use_tran_vis = use_tran_vis\n",
    "        self._ent_embeds = obj_embed\n",
    "        self.rel_embeds = rel_embed\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.ent_transfer = nn.Embedding(self.num_ent, self.embed_dim, max_norm=1.0)\n",
    "        self.rel_transfer = nn.Embedding(self.num_rel, self.embed_dim, max_norm=1.0)\n",
    "\n",
    "        r = 6/np.sqrt(self.embed_dim)\n",
    "        self.ent_transfer.weight.data.uniform_(-r, r)\n",
    "        self.rel_transfer.weight.data.uniform_(-r, r)\n",
    "        \n",
    "        self.gamma = 12.0\n",
    "        self.epsilon = 2.0\n",
    "        self.embedding_range = (self.gamma + self.epsilon) / self.embed_dim \n",
    "        \n",
    "    def transfer(self, emb, e_transfer, r_transfer):\n",
    "        return emb + (emb * e_transfer).sum(dim=1, keepdim=True) * r_transfer\n",
    "    \n",
    "    #@profile\n",
    "    def ent_embeds(self, rep, idx, rel_idx):\n",
    "            \n",
    "        if self.use_tran_vis:\n",
    "            es = rep\n",
    "        else:\n",
    "            es = self._ent_embeds(idx)\n",
    "            \n",
    "        ts = self.ent_transfer(idx)\n",
    "        \n",
    "        rel_ts = self.rel_transfer(rel_idx)\n",
    "        proj_es = self.transfer(es, ts, rel_ts)\n",
    "        return proj_es\n",
    "    \n",
    "    #def forward(self, triplets, return_ent_embed=True):\n",
    "    def forward(self, triplets, subj_rep, rel_rep, obj_rep, return_ent_emb=True):\n",
    "        pi = 3.14159265358979323846\n",
    "        \n",
    "        lhs_idxs = triplets[:, 0]\n",
    "        rel_idxs = triplets[:, 1]\n",
    "        rhs_idxs = triplets[:, 2]\n",
    "\n",
    "        if self.use_tran_vis:\n",
    "            rel_es = rel_rep\n",
    "        else:\n",
    "            rel_es = self.rel_embeds(rel_idxs)\n",
    "            \n",
    "        subj_es = self.ent_embeds(subj_rep, lhs_idxs, rel_idxs)\n",
    "        obj_es = self.ent_embeds(obj_rep, rhs_idxs, rel_idxs)\n",
    "        \n",
    "        re_head, im_head = torch.chunk(subj_es, 2, dim=1) # [512, 1, 2000]\n",
    "        re_tail, im_tail = torch.chunk(obj_es, 2, dim=1) # [512, 1, 2000]\n",
    "        \n",
    "        #Make phases of relations uniformly distributed in [-pi, pi]\n",
    "        phase_relation = rel_es/(self.embedding_range/pi) # 0.0260/pi, relation [512, 1, 1000]\n",
    "\n",
    "        re_phase, im_phase = torch.chunk(phase_relation, 2, dim=1)\n",
    "        re_relation = torch.cos(re_phase) \n",
    "        im_relation = torch.sin(im_phase)\n",
    "        \n",
    "        if self.mode == 'head-batch':\n",
    "            re_score = re_relation * re_tail + im_relation * im_tail\n",
    "            im_score = re_relation * im_tail - im_relation * re_tail\n",
    "            re_score = re_score - re_head\n",
    "            im_score = im_score - im_head\n",
    "        else: # 'tail-batch'\n",
    "            re_score = re_head * re_relation - im_head * im_relation\n",
    "            im_score = re_head * im_relation + im_head * re_relation\n",
    "            re_score = re_score - re_tail\n",
    "            im_score = im_score - im_tail\n",
    "\n",
    "        score = torch.stack([re_score, im_score], dim = 0)\n",
    "        score = score.norm(dim = 0)\n",
    "\n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        enrgs = self.gamma - score.sum(dim=1)\n",
    "        enrgs = -F.logsigmoid(enrgs)\n",
    "        \n",
    "        if not return_ent_emb:\n",
    "            return enrgs\n",
    "        else:\n",
    "            return enrgs,subj_es,obj_es,rel_es\n",
    "        \n",
    "class TransRelD(nn.Module):\n",
    "    def __init__(self, classes, rel_classes, embed_dim, p, use_tran_vis, obj_embed, rel_embed):\n",
    "        super(TransRelD, self).__init__()\n",
    "        self.num_ent = len(classes)\n",
    "        self.num_rel = len(rel_classes)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.p = p\n",
    "        \n",
    "        self.use_tran_vis = use_tran_vis\n",
    "        self._ent_embeds = obj_embed\n",
    "        self.rel_embeds = rel_embed\n",
    "        \n",
    "        self.ent_transfer = nn.Embedding(self.num_ent, self.embed_dim, max_norm=1.0)\n",
    "        self.rel_transfer = nn.Embedding(self.num_rel, self.embed_dim, max_norm=1.0)\n",
    "\n",
    "        r = 6/np.sqrt(self.embed_dim)\n",
    "        self.ent_transfer.weight.data.uniform_(-r, r)\n",
    "        self.rel_transfer.weight.data.uniform_(-r, r)\n",
    "        \n",
    "    def transfer(self, emb, e_transfer, r_transfer):\n",
    "        return emb + (emb * e_transfer).sum(dim=1, keepdim=True) * r_transfer\n",
    "    \n",
    "    #@profile\n",
    "    def ent_embeds(self, rep, idx, rel_idx):\n",
    "            \n",
    "        if self.use_tran_vis:\n",
    "            es = rep\n",
    "        else:\n",
    "            es = self._ent_embeds(idx)\n",
    "            \n",
    "        ts = self.ent_transfer(idx)\n",
    "        \n",
    "        rel_ts = self.rel_transfer(rel_idx)\n",
    "        proj_es = self.transfer(es, ts, rel_ts)\n",
    "        return proj_es\n",
    "\n",
    "    def forward(self, triplets, subj_rep, rel_rep, obj_rep, return_ent_emb=True):\n",
    "        lhs_idxs = triplets[:, 0]\n",
    "        rel_idxs = triplets[:, 1]\n",
    "        rhs_idxs = triplets[:, 2]\n",
    "        \n",
    "        if self.use_tran_vis:\n",
    "            rel_es = rel_rep\n",
    "        else:\n",
    "            rel_es = self.rel_embeds(rel_idxs)\n",
    "            \n",
    "        lhs = self.ent_embeds(subj_rep, lhs_idxs, rel_idxs)\n",
    "        rhs = self.ent_embeds(obj_rep, rhs_idxs, rel_idxs)\n",
    "        \n",
    "        if not return_ent_emb:\n",
    "            enrgs = (lhs + rel_es - rhs).norm(p=self.p, dim=1)\n",
    "            return enrgs\n",
    "        else:\n",
    "            enrgs = (lhs + rel_es - rhs).norm(p=self.p, dim=1)\n",
    "            return enrgs,lhs,rhs,rel_es\n",
    "        \n",
    "    def get_embed(self, ents, rel_idxs):\n",
    "        ent_embed = self.ent_embeds(ents, rel_idxs)\n",
    "        return ent_embed\n",
    "\n",
    "    def save(self, fn):\n",
    "        torch.save(self.state_dict(), fn)\n",
    "\n",
    "    def load(self, fn):\n",
    "        self.load_state_dict(torch.load(fn))\n",
    "        \n",
    "def rel_trans_rep_e(tranRelE, lossF, p_rels, l_rels, num_objs,subj_rep, rel_rep, obj_rep, _cb_mode, is_train=False):\n",
    "    \n",
    "    #ipdb.set_trace()\n",
    "    _cb_var = []\n",
    "    if is_train:\n",
    "        #nl_rels, q_samples = corrupt_batch(l_rels, num_objs, _cb_var, _cb_mode)\n",
    "        nl_rels, q_samples = corrupt_batch(p_rels, num_objs, _cb_var, _cb_mode)\n",
    "        d_ins = torch.cat([p_rels, l_rels, nl_rels], dim=0).contiguous()\n",
    "        \n",
    "        # prediction samples\n",
    "        if tranRelE.use_tran_vis:\n",
    "            subj_rep = subj_rep\n",
    "            rel_rep = rel_rep\n",
    "            obj_rep = obj_rep\n",
    "        else:\n",
    "            subj_rep = tranRelE._ent_embeds(p_rels[:,0])\n",
    "            #rel_rep = tranRelE.rel_embeds(p_rels[:,1])\n",
    "            rel_rep = tranRelE.rel_embeds(p_rels[:,0] * 151 + p_rels[:,2])\n",
    "            obj_rep = tranRelE._ent_embeds(p_rels[:,2])\n",
    "            \n",
    "        # positive samples\n",
    "        l_subj_rep = tranRelE._ent_embeds(l_rels[:,0])\n",
    "        #l_rel_rep = tranRelE.rel_embeds(l_rels[:,1])\n",
    "        l_rel_rep = tranRelE.rel_embeds(l_rels[:,0] * 151 + l_rels[:,2])\n",
    "        l_obj_rep = tranRelE._ent_embeds(l_rels[:,2])\n",
    "\n",
    "        # negative sample\n",
    "        nl_subj_rep = tranRelE._ent_embeds(nl_rels[:,0])\n",
    "        #nl_rel_rep = tranRelE.rel_embeds(nl_rels[:,1])\n",
    "        nl_rel_rep = tranRelE.rel_embeds(nl_rels[:,0] * 151 + nl_rels[:,2])\n",
    "        nl_obj_rep = tranRelE._ent_embeds(nl_rels[:,2])\n",
    "\n",
    "        # prediction, pos/negative samples\n",
    "        subj_rep = torch.cat([subj_rep, l_subj_rep, nl_subj_rep], dim=0).contiguous()\n",
    "        rel_rep = torch.cat([rel_rep, l_rel_rep, nl_rel_rep], dim=0).contiguous()\n",
    "        obj_rep = torch.cat([obj_rep, l_obj_rep, nl_obj_rep], dim=0).contiguous()\n",
    "        \n",
    "    else:\n",
    "        nl_rels, q_samples = corrupt_batch(p_rels, num_objs, _cb_var)\n",
    "        d_ins = torch.cat([p_rels, nl_rels], dim=0).contiguous()\n",
    "\n",
    "        # prediction samples \n",
    "        if tranRelE.use_tran_vis:\n",
    "            subj_rep = subj_rep\n",
    "            rel_rep = rel_rep\n",
    "            obj_rep = obj_rep\n",
    "        else:\n",
    "            subj_rep = tranRelE._ent_embeds(p_rels[:,0])\n",
    "            #rel_rep = tranRelE.rel_embeds(p_rels[:,1])\n",
    "            rel_rep = tranRelE.rel_embeds(p_rels[:,0] * 151 + p_rels[:,2])\n",
    "            obj_rep = tranRelE._ent_embeds(p_rels[:,2])\n",
    "\n",
    "        # negative samples \n",
    "        nl_subj_rep = tranRelE._ent_embeds(nl_rels[:,0])\n",
    "        #nl_rel_rep = tranRelE.rel_embeds(nl_rels[:,1])\n",
    "        nl_rel_rep = tranRelE.rel_embeds(nl_rels[:,0] * 151 + nl_rels[:,2])\n",
    "        nl_obj_rep = tranRelE._ent_embeds(nl_rels[:,2])\n",
    "        \n",
    "        # prediction/ negative samples\n",
    "        subj_rep = torch.cat([subj_rep, nl_subj_rep], dim=0).contiguous()\n",
    "        rel_rep = torch.cat([rel_rep, nl_rel_rep], dim=0).contiguous()\n",
    "        obj_rep = torch.cat([obj_rep, nl_obj_rep], dim=0).contiguous()\n",
    "        \n",
    "    #ipdb.set_trace()\n",
    "    #d_out, subj_out, rel_out, obj_out = tranRelE(d_ins)\n",
    "    d_out, subj_out, rel_out, obj_out = tranRelE(d_ins, subj_rep, rel_rep, obj_rep)\n",
    "    \n",
    "    #ipdb.set_trace()\n",
    "    if is_train:\n",
    "        p_rel_enrgs = d_out[:len(p_rels)]\n",
    "        l_rel_enrgs = d_out[len(p_rels):len(p_rels)*2]\n",
    "        nl_rel_enrgs = d_out[len(p_rels)*2:]\n",
    "        \n",
    "        pl_rel_score, lnl_rel_score = lossF(p_rel_enrgs, l_rel_enrgs, nl_rel_enrgs)\n",
    "        \n",
    "    else:\n",
    "        pl_rel_score = None\n",
    "        lnl_rel_score = None\n",
    "        \n",
    "    return pl_rel_score, lnl_rel_score, subj_out[:len(p_rels)], rel_out[:len(p_rels)], obj_out[:len(p_rels)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p= 1\n",
    "    num_ent = 151\n",
    "    num_rel = 51\n",
    "    embed_dim = 4096\n",
    "    \n",
    "    batch = 10\n",
    "    \n",
    "    margin = 3.0\n",
    "    #transrele = TransRelE(num_ent, num_rel, embed_dim, p)\n",
    "    transrele = TransRelD(num_ent, num_rel, embed_dim, p)\n",
    "    \n",
    "    loss_func = MarginRankingLoss(margin)\n",
    "    \n",
    "    print(transrele)\n",
    "    lhs = torch.LongTensor(batch).random_(0,num_ent)\n",
    "    rhs = torch.LongTensor(batch).random_(0,num_ent)\n",
    "    rel = torch.LongTensor(batch).random_(0,num_rel)\n",
    "    \n",
    "    p_batch = torch.stack((lhs, rel, rhs),1)\n",
    "    print(p_batch)\n",
    "    \n",
    "    nce_batch, q_samples = corrupt_batch(p_batch, num_ent)\n",
    "    nce_np = nce_batch.cpu().numpy()\n",
    "    #train_hash = bias\n",
    "    #nce_falseNs = ftensor(np.array([int(x.tobytes() in train_hash) for x in nce_np], dtype=np.float32))\n",
    "    nce_falseNs = None\n",
    "    print(nce_batch)\n",
    "    print(q_samples)\n",
    "    \n",
    "    d_ins = torch.cat([p_batch, nce_batch], dim=0).contiguous()\n",
    "    \n",
    "    d_out,lhs_out, rhs_out, rel_out = transrele(d_ins)\n",
    "    \n",
    "    #ipdb.set_trace()\n",
    "    p_enrgs = d_out[:len(p_batch)]\n",
    "    nce_enrgs = d_out[len(p_batch):]\n",
    "    #nce_term, nce_term_scores = loss_func(p_enrgs, nce_enrgs, weights=(1.- nce_falseNs))\n",
    "    nce_term, nce_term_scores = loss_func(p_enrgs, nce_enrgs)\n",
    "    print(nce_term)\n",
    "    print(nce_term_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

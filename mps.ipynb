{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.obj_message'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import optim\n",
    "import ipdb\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class obj_message(nn.Module):\n",
    "    def __init__(self,num_objs, embed_dim, opt, debug):\n",
    "        super(obj_message, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_objs = num_objs\n",
    "        \n",
    "        \"\"\"object parameters\"\"\"\n",
    "        self.ow1 = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n",
    "        self.ou1 = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n",
    "        self.ol1 = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n",
    "        self.ofc_l = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n",
    "        \n",
    "        \"\"\"object classifier\"\"\"\n",
    "        self.cls = nn.Linear(self.embed_dim, self.num_objs, bias=True)\n",
    "        \n",
    "        self.bias = 0.1\n",
    "        self.debug = debug\n",
    "        \n",
    "    def graph(self, subj,obj):\n",
    "        \"\"\" Create a graph \"\"\"\n",
    "        # subjects and objects\n",
    "        adj_matrix = Variable(\n",
    "            torch.ones([self.num_objs,self.num_objs])\n",
    "        ) * self.bias\n",
    "        \n",
    "        adj_matrix[subj,obj] = 1.0\n",
    "        adj_matrix[obj,subj] = 1.0\n",
    "        \n",
    "        l_adj_m = torch.tril(adj_matrix) * -1.0\n",
    "        u_adj_m = torch.tril(adj_matrix).transpose(0,1)\n",
    "        adj_matrix = l_adj_m + u_adj_m\n",
    "        \n",
    "        if self.debug:\n",
    "            print(adj_matrix)\n",
    "\n",
    "        return adj_matrix\n",
    "        \n",
    "    def forward(self,r_obj_rep, obj_rep, subj, obj, is_train, use_root):\n",
    "        \n",
    "        \n",
    "        if use_root:\n",
    "            norm_Q = Variable(\n",
    "                torch.ones([self.num_objs+1,self.num_objs+1])) * self.bias\n",
    "            obj_rep = torch.cat([r_obj_rep, obj_rep], 0)\n",
    "        else:\n",
    "            norm_Q = Variable(\n",
    "                torch.ones([self.num_objs,self.num_objs])) * self.bias\n",
    "        \n",
    "        sub_Q = self.graph(subj,obj)\n",
    "        \n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        mask = (sub_Q.abs() > 0).float()\n",
    "        deg_m = 1/mask.sum(1).unsqueeze(1).repeat(1,self.num_objs)\n",
    "        sub_Q = sub_Q * deg_m\n",
    "        \n",
    "        if use_root:\n",
    "            norm_Q[1:,1:] = sub_Q\n",
    "            norm_Q[1:,0] = (1.0 - norm_Q[1:,1:].sum(1))\n",
    "        else:\n",
    "            norm_Q = sub_Q\n",
    "            \n",
    "        norm_Q[norm_Q != norm_Q] = 0.0\n",
    "        \n",
    "        if self.debug:\n",
    "            print(norm_Q.sum(1))\n",
    "        \n",
    "        #norm_Q[range(self.num_objs), range(self.num_objs)] = 1.0- norm_Q.sum(1)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(norm_Q.sum(1))\n",
    "            print(norm_Q)\n",
    "            \n",
    "        \"\"\"relational object features\"\"\"\n",
    "        obj_w1 = self.ow1(F.relu(obj_rep))\n",
    "        obj_u1 = self.ou1(F.relu(obj_rep))\n",
    "        obj_l1 = self.ol1(F.relu(obj_rep))\n",
    "        \n",
    "        #import ipdb; ipdb.set_trace()\n",
    "        ofc_l = torch.matmul(norm_Q, obj_l1)\n",
    "        out_obj_rep = self.ofc_l(F.relu(ofc_l)) + obj_w1\n",
    "        \n",
    "        if use_root:\n",
    "            out_obj_rep = out_obj_rep[1:,:]\n",
    "        \n",
    "        obj_dists = self.cls(out_obj_rep)\n",
    "        \n",
    "        return obj_dists, out_obj_rep\n",
    "    \n",
    "print(obj_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:epoch:0, step:0, loss:\n",
      " 1.5706\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "train:epoch:0, step:40, loss:\n",
      " 1.5812\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "train:epoch:0, step:80, loss:\n",
      " 1.3195\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "train:epoch:0, step:120, loss:\n",
      " 1.0126\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "train:epoch:0, step:160, loss:\n",
      " 0.7953\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "test:epoch:0, step:199, loss:\n",
      " 0.5296\n",
      "[torch.FloatTensor of size 1]\n",
      ", acc:Variable containing:\n",
      " 1\n",
      "[torch.ByteTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import ipdb\n",
    "if __name__ == '__main__':\n",
    "    p= 1\n",
    "    num_obj_cls = 5\n",
    "    embed_dim = 16\n",
    "    rgb = ['c', 'y', 'b', 'r', 'm']\n",
    "    opt = ['proj', 'rotatE', 'rotatEC']\n",
    "    n_var = 0.5\n",
    "    debug = False\n",
    "    mps = 2\n",
    "    num_objs = 5\n",
    "    te_num_objs = 5\n",
    "    \n",
    "    # model and optimizer\n",
    "    obj_mps = obj_message(num_objs, embed_dim, opt[0],debug) \n",
    "    params = [p for n,p in obj_mps.named_parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params, weight_decay=0.0001, lr=0.001, eps=1e-3)\n",
    "    \n",
    "    # define object embedding\n",
    "    obj_embed = nn.Embedding(num_obj_cls, embed_dim)\n",
    "    \n",
    "    if debug:\n",
    "        steps = 1\n",
    "        epochs = 1\n",
    "        display = 1\n",
    "    else:\n",
    "        steps = 200\n",
    "        epochs = 1\n",
    "        display = 40\n",
    "        \n",
    "    rnd_objs = torch.LongTensor(te_num_objs).random_(0,num_obj_cls)\n",
    "    te_obj_labels = Variable(rnd_objs)\n",
    "    te_obj_rep = obj_embed(te_obj_labels)\n",
    "    te_r_obj_rep = te_obj_rep.sum(0).unsqueeze(0)\n",
    "            \n",
    "    te_subj = torch.LongTensor(int(num_objs/2)).random_(0,num_obj_cls)\n",
    "    te_obj = torch.LongTensor(int(num_objs/2)).random_(0,num_obj_cls)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        for step in range(steps):\n",
    "            batch = 100\n",
    "            \n",
    "            # training sets\n",
    "            rnd_objs = torch.LongTensor(num_objs).random_(0,num_obj_cls)\n",
    "            tr_obj_labels = Variable(rnd_objs)\n",
    "            tr_obj_rep = obj_embed(tr_obj_labels)\n",
    "            tr_r_obj_rep = tr_obj_rep.sum(0).unsqueeze(0)\n",
    "            \n",
    "            tr_subj = torch.LongTensor(int(num_objs/2)).random_(0,num_obj_cls)\n",
    "            tr_obj = torch.LongTensor(int(num_objs/2)).random_(0,num_obj_cls)\n",
    "                                \n",
    "            obj_mps.train()\n",
    "            for i in range(mps):\n",
    "                tr_obj_dists, tr_obj_rep = obj_mps(\n",
    "                    tr_r_obj_rep, tr_obj_rep, tr_subj, tr_obj, True, use_root=(i==0))\n",
    "\n",
    "            losses = {}\n",
    "            losses['obj_loss'] = F.cross_entropy(tr_obj_dists, tr_obj_labels)\n",
    "            loss = sum(losses.values())\n",
    "\n",
    "            ##############################\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            losses['total'] = loss\n",
    "            optimizer.step()\n",
    "            ##############################\n",
    "            \n",
    "            if step % display == 0:\n",
    "                print('train:epoch:{}, step:{}, loss:{}'.format(epoch, step,losses['total'].data))\n",
    "          \n",
    "        obj_mps.eval()\n",
    "        for i in range(mps):\n",
    "            te_obj_dists, te_obj_rep = obj_mps(\n",
    "                te_r_obj_rep, te_obj_rep, te_subj, te_obj, True, use_root=(i==0))\n",
    "\n",
    "        te_p_objs = te_obj_dists.max(1)[1]\n",
    "        te_acc = np.array(te_obj_labels == te_p_objs).sum()/te_num_objs\n",
    "        losses = {}\n",
    "        losses['total'] = F.cross_entropy(te_obj_dists, te_obj_labels)\n",
    "        loss = sum(losses.values())\n",
    "        print('test:epoch:{}, step:{}, loss:{}, acc:{}'.format(epoch, step,losses['total'].data, te_acc))\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            te_obj_labels = Variable(\n",
    "                torch.from_numpy(np.array([0,1,2,3]))).type(torch.LongTensor)\n",
    "            \n",
    "            # training sets\n",
    "            te_subj = torch.from_numpy(\n",
    "                np.array([0,0,1,1,2,3])).type(torch.LongTensor)\n",
    "            ote_bj = torch.from_numpy( \n",
    "                np.array([2,3,0,2,3,0])).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
